{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0TtbERImGdD"
      },
      "source": [
        "## GenAI Pioneer Labs: Advanced AI-Integrated App Dev: Voice Authentication System\n",
        "\n",
        "**Objective:** Build a CPU-friendly speaker recognition pipeline that:\n",
        "1. Extracts MFCC features from short audio samples.\n",
        "2. Trains a simple KNN classifier to distinguish enrolled speakers.\n",
        "3. Implements enrollment + authentication functions.\n",
        "4. Demonstrates accuracy and confidence scoring.\n",
        "\n",
        "**Skills Covered:**\n",
        "- Audio processing with `librosa`\n",
        "- Feature engineering (MFCC)\n",
        "- CPU-based machine learning (scikit-learn)\n",
        "- Model evaluation (accuracy, classification report)\n",
        "- Deployment pipeline in Google Colab\n",
        "- Documentation and code commentary for placements\n",
        "\n",
        "Voice Authentication System (Speaker Recognition)\n",
        "This Google Colab notebook guides you through building a fundamental Voice Authentication (also known as Speaker Recognition) system. This system identifies who is speaking, rather than what they are saying. It's similar to how your phone might recognize your voice to unlock.\n",
        "\n",
        "Project Overview\n",
        "We will develop a simple machine learning pipeline that can \"learn\" voices and then attempt to identify a speaker from a new, unseen voice sample.\n",
        "\n",
        "Skills Covered\n",
        "By working through this notebook, you will learn about:\n",
        "\n",
        "Environment Setup: Managing Python packages and ensuring compatibility in a Colab environment (especially important for libraries like NumPy).\n",
        "\n",
        "Audio Data Handling: Loading and processing audio files.\n",
        "\n",
        "Feature Extraction (MFCCs): Understanding and extracting Mel-frequency Cepstral Coefficients (MFCCs), which are powerful numerical representations of voice characteristics.\n",
        "\n",
        "Machine Learning Model Training: Using a simple classifier (e.g., Support Vector Machine or Random Forest) to learn patterns from voice features.\n",
        "\n",
        "Enrollment & Authentication Logic: Simulating how new speakers are \"enrolled\" into the system and how unknown voices are \"authenticated\" against known ones.\n",
        "\n",
        "Model Evaluation: Basic understanding of how to test if our system is working.\n",
        "\n",
        "CPU-Only Processing: Ensuring our entire system runs efficiently without needing a GPU, making it accessible to more users.\n"
      ],
      "id": "L0TtbERImGdD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Environment Setup & NumPy Control\n",
        "\n",
        "# This cell installs all necessary libraries and *crucially* ensures a specific\n",
        "# NumPy version is loaded. This will cause a runtime restart.\n",
        "\n",
        "print(\"--- Starting Environment Setup ---\")\n",
        "print(\"1. Installing core libraries: librosa, soundfile, scikit-learn, matplotlib, Pillow...\")\n",
        "\n",
        "# librosa: For audio feature extraction (MFCCs)\n",
        "# soundfile: For robust audio file reading/writing (used by librosa)\n",
        "# scikit-learn: For building our machine learning classifier\n",
        "# matplotlib: For plotting/visualization\n",
        "# Pillow: For image handling (though not strictly needed here, good practice for general ML setups)\n",
        "!pip install librosa soundfile scikit-learn matplotlib Pillow\n",
        "\n",
        "print(\"\\n2. Ensuring NumPy compatibility (this will force a restart)...\")\n",
        "# NumPy version control is critical due to recent changes in Colab and\n",
        "# potential incompatibilities with other libraries.\n",
        "# We explicitly install a stable NumPy 1.x version.\n",
        "# '--force-reinstall' ensures it replaces any existing version.\n",
        "!pip install numpy==1.26.4 --force-reinstall\n",
        "\n",
        "print(\"\\n-------------------------------------------------------------\")\n",
        "print(\"Installation complete for now. YOU MUST RESTART THE RUNTIME!\")\n",
        "print(\"Look for the 'Restart runtime' button/prompt and click it.\")\n",
        "print(\"After restarting, run all cells again from the beginning.\")\n",
        "print(\"-------------------------------------------------------------\\n\")\n",
        "\n",
        "# This command will terminate the current Python session.\n",
        "# Cell 1: Environment Setup & NumPy Control\n",
        "\n",
        "# This cell installs all necessary libraries and *crucially* ensures a specific\n",
        "# NumPy version is loaded. This will cause a runtime restart.\n",
        "\n",
        "print(\"--- Starting Environment Setup ---\")\n",
        "print(\"1. Installing core libraries: librosa, soundfile, scikit-learn, matplotlib, Pillow...\")\n",
        "\n",
        "# librosa: For audio feature extraction (MFCCs)\n",
        "# soundfile: For robust audio file reading/writing (used by librosa)\n",
        "# scikit-learn: For building our machine learning classifier\n",
        "# matplotlib: For plotting/visualization\n",
        "# Pillow: For image handling (though not strictly needed here, good practice for general ML setups)\n",
        "!pip install librosa soundfile scikit-learn matplotlib Pillow\n",
        "\n",
        "print(\"\\n2. Ensuring NumPy compatibility (this will force a restart)...\")\n",
        "# NumPy version control is critical due to recent changes in Colab and\n",
        "# potential incompatibilities with other libraries.\n",
        "# We explicitly install a stable NumPy 1.x version.\n",
        "# '--force-reinstall' ensures it replaces any existing version.\n",
        "!pip install numpy==1.26.4 --force-reinstall\n",
        "\n",
        "print(\"\\n-------------------------------------------------------------\")\n",
        "print(\"Installation complete for now. YOU MUST RESTART THE RUNTIME!\")\n",
        "print(\"Look for the 'Restart runtime' button/prompt and click it.\")\n",
        "print(\"After restarting, run all cells again from the beginning.\")\n",
        "print(\"-------------------------------------------------------------\\n\")\n",
        "\n",
        "# This command will terminate the current Python session.\n",
        "# Cell 1: Environment Setup & NumPy Control\n",
        "\n",
        "# This cell installs all necessary libraries and *crucially* ensures a specific\n",
        "# NumPy version is loaded. This will cause a runtime restart.\n",
        "\n",
        "print(\"--- Starting Environment Setup ---\")\n",
        "print(\"1. Installing core libraries: librosa, soundfile, scikit-learn, matplotlib, Pillow...\")\n",
        "\n",
        "# librosa: For audio feature extraction (MFCCs)\n",
        "# soundfile: For robust audio file reading/writing (used by librosa)\n",
        "# scikit-learn: For building our machine learning classifier\n",
        "# matplotlib: For plotting/visualization\n",
        "# Pillow: For image handling (though not strictly needed here, good practice for general ML setups)\n",
        "!pip install librosa soundfile scikit-learn matplotlib Pillow\n",
        "\n",
        "print(\"\\n2. Ensuring NumPy compatibility (this will force a restart)...\")\n",
        "# NumPy version control is critical due to recent changes in Colab and\n",
        "# potential incompatibilities with other libraries.\n",
        "# We explicitly install a stable NumPy 1.x version.\n",
        "# '--force-reinstall' ensures it replaces any existing version.\n",
        "!pip install numpy==1.26.4 --force-reinstall\n",
        "\n",
        "print(\"\\n-------------------------------------------------------------\")\n",
        "print(\"Installation complete for now. YOU MUST RESTART THE RUNTIME!\")\n",
        "print(\"Look for the 'Restart runtime' button/prompt and click it.\")\n",
        "print(\"After restarting, run all cells again from the beginning.\")\n",
        "print(\"-------------------------------------------------------------\\n\")\n",
        "\n",
        "# This command will terminate the current Python session.\n",
        "# In Colab, this typically triggers a prompt to restart the runtime cleanly.\n",
        "exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_jDP5e3qFQd",
        "outputId": "17dd4544-c128-43f6-d019-422987a49ef3"
      },
      "id": "N_jDP5e3qFQd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Environment Setup ---\n",
            "1. Installing core libraries: librosa, soundfile, scikit-learn, matplotlib, Pillow...\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "\n",
            "2. Ensuring NumPy compatibility (this will force a restart)...\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Installation complete for now. YOU MUST RESTART THE RUNTIME!\n",
            "Look for the 'Restart runtime' button/prompt and click it.\n",
            "After restarting, run all cells again from the beginning.\n",
            "-------------------------------------------------------------\n",
            "\n",
            "--- Starting Environment Setup ---\n",
            "1. Installing core libraries: librosa, soundfile, scikit-learn, matplotlib, Pillow...\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "\n",
            "2. Ensuring NumPy compatibility (this will force a restart)...\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Installation complete for now. YOU MUST RESTART THE RUNTIME!\n",
            "Look for the 'Restart runtime' button/prompt and click it.\n",
            "After restarting, run all cells again from the beginning.\n",
            "-------------------------------------------------------------\n",
            "\n",
            "--- Starting Environment Setup ---\n",
            "1. Installing core libraries: librosa, soundfile, scikit-learn, matplotlib, Pillow...\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "\n",
            "2. Ensuring NumPy compatibility (this will force a restart)...\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Installation complete for now. YOU MUST RESTART THE RUNTIME!\n",
            "Look for the 'Restart runtime' button/prompt and click it.\n",
            "After restarting, run all cells again from the beginning.\n",
            "-------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Re-Import Libraries & Verify Setup\n",
        "\n",
        "# This cell should be run *after* the runtime has been restarted from Cell 1.\n",
        "# It re-imports libraries and verifies that our NumPy version is correctly loaded.\n",
        "\n",
        "print(\"--- Re-Importing Libraries ---\")\n",
        "\n",
        "# Import standard libraries\n",
        "import numpy as np        # Numerical operations (should be 1.26.4 now)\n",
        "import matplotlib.pyplot as plt # Plotting library\n",
        "import time               # For timing operations\n",
        "import os                 # Operating system interactions (e.g., path creation)\n",
        "\n",
        "# Import machine learning and audio processing libraries\n",
        "import librosa            # For Mel-frequency Cepstral Coefficients (MFCCs)\n",
        "import soundfile as sf    # Used by librosa for specific audio formats\n",
        "from sklearn.svm import SVC # Support Vector Classifier for our model\n",
        "from sklearn.ensemble import RandomForestClassifier # Another good classifier option\n",
        "from sklearn.model_selection import train_test_split # For splitting data\n",
        "from sklearn.metrics import accuracy_score, classification_report # For evaluation\n",
        "from sklearn.preprocessing import StandardScaler # For scaling features\n",
        "\n",
        "# Import Colab-specific tools for file upload\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Libraries re-imported. Verifying NumPy version...\")\n",
        "# Verify the NumPy version to ensure the downgrade was successful.\n",
        "print(f\"NumPy version currently loaded: {np.__version__}\")\n",
        "\n",
        "# Check if it's the expected version\n",
        "if np.__version__ == '1.26.4':\n",
        "    print(\"NumPy version is correct (1.26.4). Good to go!\")\n",
        "else:\n",
        "    print(\"WARNING: NumPy version might not be 1.26.4. If you face errors, manually restart runtime ('Runtime' -> 'Restart session') and try again.\")\n",
        "# Cell 2: Re-Import Libraries & Verify Setup\n",
        "\n",
        "# This cell should be run *after* the runtime has been restarted from Cell 1.\n",
        "# It re-imports libraries and verifies that our NumPy version is correctly loaded.\n",
        "\n",
        "print(\"--- Re-Importing Libraries ---\")\n",
        "\n",
        "# Import standard libraries\n",
        "import numpy as np        # Numerical operations (should be 1.26.4 now)\n",
        "import matplotlib.pyplot as plt # Plotting library\n",
        "import time               # For timing operations\n",
        "import os                 # Operating system interactions (e.g., path creation)\n",
        "\n",
        "# Import machine learning and audio processing libraries\n",
        "import librosa            # For Mel-frequency Cepstral Coefficients (MFCCs)\n",
        "import soundfile as sf    # Used by librosa for specific audio formats\n",
        "from sklearn.svm import SVC # Support Vector Classifier for our model\n",
        "from sklearn.ensemble import RandomForestClassifier # Another good classifier option\n",
        "from sklearn.model_selection import train_test_split # For splitting data\n",
        "from sklearn.metrics import accuracy_score, classification_report # For evaluation\n",
        "from sklearn.preprocessing import StandardScaler # For scaling features\n",
        "\n",
        "# Import Colab-specific tools for file upload\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Libraries re-imported. Verifying NumPy version...\")\n",
        "# Verify the NumPy version to ensure the downgrade was successful.\n",
        "print(f\"NumPy version currently loaded: {np.__version__}\")\n",
        "\n",
        "# Check if it's the expected version\n",
        "if np.__version__ == '1.26.4':\n",
        "    print(\"NumPy version is correct (1.26.4). Good to go!\")\n",
        "else:\n",
        "    print(\"WARNING: NumPy version might not be 1.26.4. If you face errors, manually restart runtime ('Runtime' -> 'Restart session') and try again.\")\n",
        "\n",
        "print(\"\\nSetup verification complete. Proceed to next cell.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZiRZHfwF2xR",
        "outputId": "65333610-5ecc-40a0-8d3a-c397c2253e6d"
      },
      "id": "4ZiRZHfwF2xR",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Re-Importing Libraries ---\n",
            "Libraries re-imported. Verifying NumPy version...\n",
            "NumPy version currently loaded: 1.26.4\n",
            "NumPy version is correct (1.26.4). Good to go!\n",
            "--- Re-Importing Libraries ---\n",
            "Libraries re-imported. Verifying NumPy version...\n",
            "NumPy version currently loaded: 1.26.4\n",
            "NumPy version is correct (1.26.4). Good to go!\n",
            "\n",
            "Setup verification complete. Proceed to next cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FkqCJs4mGdI"
      },
      "source": [
        "## 3. Data Preparation\n",
        "\n",
        "1. Create a `voice_data.zip` structured as:\n",
        "   ```\n",
        "   voice_data/\n",
        "   ├── speaker_A/\n",
        "   │   ├── A_01.wav\n",
        "   │   └── ...\n",
        "   ├── speaker_B/\n",
        "   │   ├── B_01.wav\n",
        "   │   └── ...\n",
        "   └── speaker_C/\n",
        "       ├── C_01.wav\n",
        "       └── ...\n",
        "   ```\n",
        "\n",
        "2. Each WAV: 16 kHz, 16-bit PCM, 2–5 sec, passphrase.\n"
      ],
      "id": "-FkqCJs4mGdI"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aiDvqpysFxEA"
      },
      "id": "aiDvqpysFxEA",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNADx4SEmGdK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "9fe5a4d6-b52f-4cf0-9430-f4e21924f299"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Preparation: Upload Your Audio Samples ---\n",
            "Please upload your .wav audio files now. (e.g., speaker1_enroll_01.wav, speaker2_test_01.wav)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-90d9f5d7-52ed-42df-bbd9-ed65a87d67b9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-90d9f5d7-52ed-42df-bbd9-ed65a87d67b9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving speaker1_enroll_01.wav to speaker1_enroll_01.wav\n",
            "Saving speaker1_enroll_02.wav to speaker1_enroll_02.wav\n",
            "Saving speaker1_enroll_03.wav to speaker1_enroll_03.wav\n",
            "Saving speaker2_enroll_01.wav to speaker2_enroll_01.wav\n",
            "Saving speaker2_enroll_02.wav to speaker2_enroll_02.wav\n",
            "Saving speaker2_enroll_03.wav to speaker2_enroll_03.wav\n",
            "Saving speaker2_test_01.wav to speaker2_test_01.wav\n",
            "Saving speaker2_test_02.wav to speaker2_test_02.wav\n",
            "Saving speaker2_test_03.wav to speaker2_test_03.wav\n",
            "Saving speaker1_test_01.wav to speaker1_test_01.wav\n",
            "Saving speaker1_test_02.wav to speaker1_test_02.wav\n",
            "Saving speaker1_test_03.wav to speaker1_test_03.wav\n",
            "\n",
            "Processing uploaded files...\n",
            "  Moved 'speaker1_enroll_01.wav' to 'enrollment_samples/speaker1_enroll_01.wav'\n",
            "  Moved 'speaker1_enroll_02.wav' to 'enrollment_samples/speaker1_enroll_02.wav'\n",
            "  Moved 'speaker1_enroll_03.wav' to 'enrollment_samples/speaker1_enroll_03.wav'\n",
            "  Moved 'speaker2_enroll_01.wav' to 'enrollment_samples/speaker2_enroll_01.wav'\n",
            "  Moved 'speaker2_enroll_02.wav' to 'enrollment_samples/speaker2_enroll_02.wav'\n",
            "  Moved 'speaker2_enroll_03.wav' to 'enrollment_samples/speaker2_enroll_03.wav'\n",
            "  Moved 'speaker2_test_01.wav' to 'test_samples/speaker2_test_01.wav'\n",
            "  Moved 'speaker2_test_02.wav' to 'test_samples/speaker2_test_02.wav'\n",
            "  Moved 'speaker2_test_03.wav' to 'test_samples/speaker2_test_03.wav'\n",
            "  Moved 'speaker1_test_01.wav' to 'test_samples/speaker1_test_01.wav'\n",
            "  Moved 'speaker1_test_02.wav' to 'test_samples/speaker1_test_02.wav'\n",
            "  Moved 'speaker1_test_03.wav' to 'test_samples/speaker1_test_03.wav'\n",
            "\n",
            "Audio file organization complete.\n",
            "Total uploaded files: 12\n",
            "Enrollment files: 6\n",
            "Test files: 6\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Data Preparation: Uploading Audio Samples\n",
        "\n",
        "# In this cell, you will upload your audio files for speaker enrollment and testing.\n",
        "# Please create a few short .wav files for 2-3 distinct speakers.\n",
        "# For each speaker, have:\n",
        "# - At least 2-3 ENROLLMENT samples (e.g., 'speaker1_enroll_01.wav', 'speaker1_enroll_02.wav')\n",
        "# - At least 1 TEST sample (e.g., 'speaker1_test_01.wav')\n",
        "\n",
        "# Example file naming convention:\n",
        "# speaker_name_type_number.wav\n",
        "# e.g., 'john_enroll_01.wav', 'john_enroll_02.wav', 'jane_enroll_01.wav', 'jane_test_01.wav'\n",
        "\n",
        "print(\"--- Data Preparation: Upload Your Audio Samples ---\")\n",
        "print(\"Please upload your .wav audio files now. (e.g., speaker1_enroll_01.wav, speaker2_test_01.wav)\")\n",
        "\n",
        "# Create directories for organizing audio files\n",
        "enrollment_dir = 'enrollment_samples'\n",
        "test_dir = 'test_samples'\n",
        "os.makedirs(enrollment_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Upload files from your local machine\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "print(\"\\nProcessing uploaded files...\")\n",
        "\n",
        "# List to store information about uploaded files\n",
        "all_audio_files = []\n",
        "\n",
        "# Iterate through uploaded files and move them to appropriate directories\n",
        "for filename in uploaded_files.keys():\n",
        "    # Example parsing: 'speaker_name_type_number.wav'\n",
        "    # This assumes a specific naming convention.\n",
        "    parts = filename.split('_')\n",
        "    speaker_name = parts[0]\n",
        "    sample_type = parts[1] # 'enroll' or 'test'\n",
        "\n",
        "    destination_path = \"\"\n",
        "    if sample_type == 'enroll':\n",
        "        destination_path = os.path.join(enrollment_dir, filename)\n",
        "    elif sample_type == 'test':\n",
        "        destination_path = os.path.join(test_dir, filename)\n",
        "    else:\n",
        "        print(f\"Skipping unknown file type: {filename}. Please use 'enroll' or 'test' in filename.\")\n",
        "        continue\n",
        "\n",
        "    # Move the file from Colab's default upload location to our organized directory\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(uploaded_files[filename])\n",
        "    os.rename(filename, destination_path) # Move the file\n",
        "\n",
        "    all_audio_files.append({'speaker': speaker_name, 'type': sample_type, 'path': destination_path})\n",
        "    print(f\"  Moved '{filename}' to '{destination_path}'\")\n",
        "\n",
        "print(\"\\nAudio file organization complete.\")\n",
        "print(f\"Total uploaded files: {len(all_audio_files)}\")\n",
        "print(f\"Enrollment files: {len([f for f in all_audio_files if f['type'] == 'enroll'])}\")\n",
        "print(f\"Test files: {len([f for f in all_audio_files if f['type'] == 'test'])}\")"
      ],
      "id": "ZNADx4SEmGdK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwoDrilgmGdM"
      },
      "source": [
        "## 4. Feature Extraction (MFCC)\n",
        "\n",
        "We’ll extract 13 MFCCs per frame, then compute mean + variance → 26-dim vector.\n"
      ],
      "id": "UwoDrilgmGdM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDE3k_Z1mGdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39561db3-086a-41bc-e1a3-124b5a2a9dee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Feature Extraction (MFCCs) ---\n",
            "\n",
            "Extracting MFCCs from enrollment samples...\n",
            "  Extracted MFCCs for speaker1 from speaker1_enroll_01.wav\n",
            "  Extracted MFCCs for speaker1 from speaker1_enroll_02.wav\n",
            "  Extracted MFCCs for speaker1 from speaker1_enroll_03.wav\n",
            "  Extracted MFCCs for speaker2 from speaker2_enroll_01.wav\n",
            "  Extracted MFCCs for speaker2 from speaker2_enroll_02.wav\n",
            "  Extracted MFCCs for speaker2 from speaker2_enroll_03.wav\n",
            "\n",
            "MFCC extraction complete.\n",
            "Shape of features (X): (6, 13)\n",
            "Shape of labels (y): (6,)\n",
            "--- Feature Extraction (MFCCs) ---\n",
            "\n",
            "Extracting MFCCs from enrollment samples...\n",
            "  Extracted MFCCs for speaker1 from speaker1_enroll_01.wav\n",
            "  Extracted MFCCs for speaker1 from speaker1_enroll_02.wav\n",
            "  Extracted MFCCs for speaker1 from speaker1_enroll_03.wav\n",
            "  Extracted MFCCs for speaker2 from speaker2_enroll_01.wav\n",
            "  Extracted MFCCs for speaker2 from speaker2_enroll_02.wav\n",
            "  Extracted MFCCs for speaker2 from speaker2_enroll_03.wav\n",
            "\n",
            "MFCC extraction complete.\n",
            "Shape of features (X): (6, 13)\n",
            "Shape of labels (y): (6,)\n",
            "Features ready for training!\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Feature Extraction (MFCCs)\n",
        "\n",
        "# This cell defines a function to extract MFCCs (Mel-frequency Cepstral Coefficients)\n",
        "# from audio files. MFCCs are widely used in speech recognition because they\n",
        "# effectively represent the short-term power spectrum of a sound.\n",
        "\n",
        "print(\"--- Feature Extraction (MFCCs) ---\")\n",
        "\n",
        "# Define parameters for MFCC extraction\n",
        "# sr (sampling rate): How many samples per second in the audio. 22050 is common.\n",
        "# n_mfcc: Number of MFCCs to extract. 13-20 is typical.\n",
        "SAMPLING_RATE = 22050\n",
        "N_MFCC = 13 # Number of MFCCs to extract per frame\n",
        "\n",
        "def extract_mfcc(audio_path, sr=SAMPLING_RATE, n_mfcc=N_MFCC):\n",
        "    \"\"\"\n",
        "    Loads an audio file and extracts its MFCCs.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file.\n",
        "        sr (int): Sampling rate.\n",
        "        n_mfcc (int): Number of MFCC coefficients.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Averaged MFCCs, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the audio file\n",
        "        # 'y' is the audio time series (waveform)\n",
        "        # 'sr' is the sampling rate\n",
        "        y, loaded_sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Extract MFCC features from the audio waveform\n",
        "        # librosa.feature.mfcc returns an array where each column is an MFCC vector for a frame.\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=loaded_sr, n_mfcc=n_mfcc)\n",
        "\n",
        "        # For simplicity in this basic classifier, we average the MFCCs across all frames.\n",
        "        # This reduces each audio sample to a single vector of length n_mfcc.\n",
        "        averaged_mfccs = np.mean(mfccs.T, axis=0)\n",
        "\n",
        "        return averaged_mfccs\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Lists to store features and corresponding labels\n",
        "X_features = [] # To store MFCC features\n",
        "y_labels = []   # To store speaker labels\n",
        "\n",
        "print(\"\\nExtracting MFCCs from enrollment samples...\")\n",
        "# Loop through all enrollment files and extract features\n",
        "enrollment_files_info = [f for f in all_audio_files if f['type'] == 'enroll']\n",
        "for file_info in enrollment_files_info:\n",
        "    mfcc_vector = extract_mfcc(file_info['path'])\n",
        "    if mfcc_vector is not None:\n",
        "        X_features.append(mfcc_vector)\n",
        "        y_labels.append(file_info['speaker'])\n",
        "        print(f\"  Extracted MFCCs for {file_info['speaker']} from {os.path.basename(file_info['path'])}\")\n",
        "\n",
        "# Convert lists to NumPy arrays for machine learning\n",
        "X_features = np.array(X_features)\n",
        "y_labels = np.array(y_labels)\n",
        "\n",
        "print(\"\\nMFCC extraction complete.\")\n",
        "print(f\"Shape of features (X): {X_features.shape}\")\n",
        "print(f\"Shape of labels (y): {y_labels.shape}\")\n",
        "\n",
        "if X_features.shape[0] == 0:\n",
        "    print(\"WARNING: No features extracted. Please ensure you uploaded valid audio files following the naming convention.\")\n",
        "# Cell 4: Feature Extraction (MFCCs)\n",
        "\n",
        "# This cell defines a function to extract MFCCs (Mel-frequency Cepstral Coefficients)\n",
        "# from audio files. MFCCs are widely used in speech recognition because they\n",
        "# effectively represent the short-term power spectrum of a sound.\n",
        "\n",
        "print(\"--- Feature Extraction (MFCCs) ---\")\n",
        "\n",
        "# Define parameters for MFCC extraction\n",
        "# sr (sampling rate): How many samples per second in the audio. 22050 is common.\n",
        "# n_mfcc: Number of MFCCs to extract. 13-20 is typical.\n",
        "SAMPLING_RATE = 22050\n",
        "N_MFCC = 13 # Number of MFCCs to extract per frame\n",
        "\n",
        "import librosa # Assuming librosa is installed and imported earlier\n",
        "import numpy as np # Assuming numpy is installed and imported earlier\n",
        "import os # Assuming os is installed and imported earlier\n",
        "\n",
        "\n",
        "def extract_mfcc(audio_path, sr=SAMPLING_RATE, n_mfcc=N_MFCC):\n",
        "    \"\"\"\n",
        "    Loads an audio file and extracts its MFCCs.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file.\n",
        "        sr (int): Sampling rate.\n",
        "        n_mfcc (int): Number of MFCC coefficients.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Averaged MFCCs, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the audio file\n",
        "        # 'y' is the audio time series (waveform)\n",
        "        # 'sr' is the sampling rate\n",
        "        y, loaded_sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Extract MFCC features from the audio waveform\n",
        "        # librosa.feature.mfcc returns an array where each column is an MFCC vector for a frame.\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=loaded_sr, n_mfcc=n_mfcc)\n",
        "\n",
        "        # For simplicity in this basic classifier, we average the MFCCs across all frames.\n",
        "        # This reduces each audio sample to a single vector of length n_mfcc.\n",
        "        averaged_mfccs = np.mean(mfccs.T, axis=0)\n",
        "\n",
        "        return averaged_mfccs\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Lists to store features and corresponding labels\n",
        "X_features = [] # To store MFCC features\n",
        "y_labels = []   # To store speaker labels\n",
        "\n",
        "print(\"\\nExtracting MFCCs from enrollment samples...\")\n",
        "# Loop through all enrollment files and extract features\n",
        "enrollment_files_info = [f for f in all_audio_files if f['type'] == 'enroll']\n",
        "for file_info in enrollment_files_info:\n",
        "    mfcc_vector = extract_mfcc(file_info['path'])\n",
        "    if mfcc_vector is not None:\n",
        "        X_features.append(mfcc_vector)\n",
        "        y_labels.append(file_info['speaker'])\n",
        "        print(f\"  Extracted MFCCs for {file_info['speaker']} from {os.path.basename(file_info['path'])}\")\n",
        "\n",
        "# Convert lists to NumPy arrays for machine learning\n",
        "X_features = np.array(X_features)\n",
        "y_labels = np.array(y_labels)\n",
        "\n",
        "print(\"\\nMFCC extraction complete.\")\n",
        "print(f\"Shape of features (X): {X_features.shape}\")\n",
        "print(f\"Shape of labels (y): {y_labels.shape}\")\n",
        "\n",
        "if X_features.shape[0] == 0:\n",
        "    print(\"WARNING: No features extracted. Please ensure you uploaded valid audio files following the naming convention.\")\n",
        "else:\n",
        "    print(\"Features ready for training!\")"
      ],
      "id": "eDE3k_Z1mGdO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKR-0d3pmGdP"
      },
      "source": [
        "## 5. Model Training\n",
        "\n",
        "1. Traverse `voice_data/{speaker}/*.wav`\n",
        "2. Extract MFCCs, build X, y\n",
        "3. Split 80/20, train KNN (k=3, Euclidean)\n",
        "4. Evaluate on test set\n"
      ],
      "id": "PKR-0d3pmGdP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77B_twD_mGdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78132cc0-3561-44c8-d507-3495b8516e01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model Training ---\n",
            "Features scaled. Shape: (6, 13)\n",
            "Data split: Train samples=4, Test samples=2\n",
            "\n",
            "Training the model...\n",
            "Model training complete in 0.0 seconds.\n",
            "\n",
            "Model accuracy on internal test set: 100.00%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    speaker1       1.00      1.00      1.00         1\n",
            "    speaker2       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "--- Model Training ---\n",
            "Features scaled. Shape: (6, 13)\n",
            "Data split: Train samples=4, Test samples=2\n",
            "\n",
            "Training the model...\n",
            "Model training complete in 0.0 seconds.\n",
            "\n",
            "Model accuracy on internal test set: 100.00%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    speaker1       1.00      1.00      1.00         1\n",
            "    speaker2       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "\n",
            "Model trained and ready for authentication!\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Model Training (Simple Classifier on CPU)\n",
        "\n",
        "# Now that we have our numerical features (MFCCs) and speaker labels,\n",
        "# we can train a machine learning model to learn the association between them.\n",
        "# We'll use a Support Vector Classifier (SVC) as a robust choice,\n",
        "# but a RandomForestClassifier could also be used.\n",
        "\n",
        "print(\"--- Model Training ---\")\n",
        "\n",
        "if X_features.shape[0] < 2 or len(np.unique(y_labels)) < 2:\n",
        "    print(\"ERROR: Not enough data or unique speakers to train a model.\")\n",
        "    print(\"Please upload at least 2 enrollment samples for at least 2 distinct speakers.\")\n",
        "else:\n",
        "    # Scale the features\n",
        "    # Scaling is important for many ML algorithms (like SVC) to ensure\n",
        "    # all features contribute equally, regardless of their original scale.\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_features)\n",
        "    print(f\"Features scaled. Shape: {X_scaled.shape}\")\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    # This helps us evaluate how well our model performs on unseen data.\n",
        "    # test_size=0.2 means 20% of data will be for testing, 80% for training.\n",
        "    # random_state ensures reproducibility of the split.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y_labels, test_size=0.2, random_state=42, stratify=y_labels\n",
        "    )\n",
        "    print(f\"Data split: Train samples={X_train.shape[0]}, Test samples={X_test.shape[0]}\")\n",
        "\n",
        "    # Initialize the Support Vector Classifier model\n",
        "    # C=1.0 is a regularization parameter. kernel='linear' uses a linear decision boundary.\n",
        "    # The model will run on CPU by default.\n",
        "    model = SVC(kernel='linear', C=1.0, random_state=42, probability=True)\n",
        "    # Alternatively, you could use a RandomForestClassifier:\n",
        "    # model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    print(\"\\nTraining the model...\")\n",
        "    train_start_time = time.time()\n",
        "    model.fit(X_train, y_train) # Train the model using the training data\n",
        "    train_end_time = time.time()\n",
        "    print(f\"Model training complete in {round(train_end_time - train_start_time, 2)} seconds.\")\n",
        "\n",
        "    # Evaluate the model's performance on the test set (sanity check)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nModel accuracy on internal test set: {accuracy * 100:.2f}%\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "# Cell 5: Model Training (Simple Classifier on CPU)\n",
        "\n",
        "# Now that we have our numerical features (MFCCs) and speaker labels,\n",
        "# we can train a machine learning model to learn the association between them.\n",
        "# We'll use a Support Vector Classifier (SVC) as a robust choice,\n",
        "# but a RandomForestClassifier could also be used.\n",
        "\n",
        "print(\"--- Model Training ---\")\n",
        "\n",
        "if X_features.shape[0] < 2 or len(np.unique(y_labels)) < 2:\n",
        "    print(\"ERROR: Not enough data or unique speakers to train a model.\")\n",
        "    print(\"Please upload at least 2 enrollment samples for at least 2 distinct speakers.\")\n",
        "else:\n",
        "    # Scale the features\n",
        "    # Scaling is important for many ML algorithms (like SVC) to ensure\n",
        "    # all features contribute equally, regardless of their original scale.\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_features)\n",
        "    print(f\"Features scaled. Shape: {X_scaled.shape}\")\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    # This helps us evaluate how well our model performs on unseen data.\n",
        "    # test_size=0.2 means 20% of data will be for testing, 80% for training.\n",
        "    # random_state ensures reproducibility of the split.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y_labels, test_size=0.2, random_state=42, stratify=y_labels\n",
        "    )\n",
        "    print(f\"Data split: Train samples={X_train.shape[0]}, Test samples={X_test.shape[0]}\")\n",
        "\n",
        "    # Initialize the Support Vector Classifier model\n",
        "    # C=1.0 is a regularization parameter. kernel='linear' uses a linear decision boundary.\n",
        "    # The model will run on CPU by default.\n",
        "    model = SVC(kernel='linear', C=1.0, random_state=42, probability=True)\n",
        "    # Alternatively, you could use a RandomForestClassifier:\n",
        "    # model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    print(\"\\nTraining the model...\")\n",
        "    train_start_time = time.time()\n",
        "    model.fit(X_train, y_train) # Train the model using the training data\n",
        "    train_end_time = time.time()\n",
        "    print(f\"Model training complete in {round(train_end_time - train_start_time, 2)} seconds.\")\n",
        "\n",
        "    # Evaluate the model's performance on the test set (sanity check)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nModel accuracy on internal test set: {accuracy * 100:.2f}%\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nModel trained and ready for authentication!\")\n"
      ],
      "id": "77B_twD_mGdQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfhMq0WQmGdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166738e1-21af-4c4a-bf24-816cd29929d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Authentication Logic ---\n",
            "\n",
            "Performing authentication on test samples...\n",
            "\n",
            "--- Test Sample 1: 'speaker2_test_01.wav' (True speaker: speaker2) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker2\n",
            "Probabilities per speaker:\n",
            "  speaker1: 25.00%\n",
            "  speaker2: 75.00%\n",
            "Status: AUTHENTICATED (Correctly identified)\n",
            "\n",
            "--- Test Sample 2: 'speaker2_test_02.wav' (True speaker: speaker2) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker2\n",
            "Probabilities per speaker:\n",
            "  speaker1: 25.00%\n",
            "  speaker2: 75.00%\n",
            "Status: AUTHENTICATED (Correctly identified)\n",
            "\n",
            "--- Test Sample 3: 'speaker2_test_03.wav' (True speaker: speaker2) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker2\n",
            "Probabilities per speaker:\n",
            "  speaker1: 25.00%\n",
            "  speaker2: 75.00%\n",
            "Status: AUTHENTICATED (Correctly identified)\n",
            "\n",
            "--- Test Sample 4: 'speaker1_test_01.wav' (True speaker: speaker1) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker1\n",
            "Probabilities per speaker:\n",
            "  speaker1: 26.60%\n",
            "  speaker2: 73.40%\n",
            "Status: FAILED AUTHENTICATION (Incorrectly identified)\n",
            "\n",
            "--- Test Sample 5: 'speaker1_test_02.wav' (True speaker: speaker1) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker1\n",
            "Probabilities per speaker:\n",
            "  speaker1: 26.60%\n",
            "  speaker2: 73.40%\n",
            "Status: FAILED AUTHENTICATION (Incorrectly identified)\n",
            "\n",
            "--- Test Sample 6: 'speaker1_test_03.wav' (True speaker: speaker1) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker1\n",
            "Probabilities per speaker:\n",
            "  speaker1: 26.60%\n",
            "  speaker2: 73.40%\n",
            "Status: FAILED AUTHENTICATION (Incorrectly identified)\n",
            "--- Authentication Logic ---\n",
            "\n",
            "Performing authentication on test samples...\n",
            "\n",
            "--- Test Sample 1: 'speaker2_test_01.wav' (True speaker: speaker2) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker2\n",
            "Probabilities per speaker:\n",
            "  speaker1: 25.00%\n",
            "  speaker2: 75.00%\n",
            "Status: AUTHENTICATED (Correctly identified)\n",
            "\n",
            "--- Test Sample 2: 'speaker2_test_02.wav' (True speaker: speaker2) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker2\n",
            "Probabilities per speaker:\n",
            "  speaker1: 25.00%\n",
            "  speaker2: 75.00%\n",
            "Status: AUTHENTICATED (Correctly identified)\n",
            "\n",
            "--- Test Sample 3: 'speaker2_test_03.wav' (True speaker: speaker2) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker2\n",
            "Probabilities per speaker:\n",
            "  speaker1: 25.00%\n",
            "  speaker2: 75.00%\n",
            "Status: AUTHENTICATED (Correctly identified)\n",
            "\n",
            "--- Test Sample 4: 'speaker1_test_01.wav' (True speaker: speaker1) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker1\n",
            "Probabilities per speaker:\n",
            "  speaker1: 26.60%\n",
            "  speaker2: 73.40%\n",
            "Status: FAILED AUTHENTICATION (Incorrectly identified)\n",
            "\n",
            "--- Test Sample 5: 'speaker1_test_02.wav' (True speaker: speaker1) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker1\n",
            "Probabilities per speaker:\n",
            "  speaker1: 26.60%\n",
            "  speaker2: 73.40%\n",
            "Status: FAILED AUTHENTICATION (Incorrectly identified)\n",
            "\n",
            "--- Test Sample 6: 'speaker1_test_03.wav' (True speaker: speaker1) ---\n",
            "Predicted Speaker: speaker2\n",
            "True Speaker: speaker1\n",
            "Probabilities per speaker:\n",
            "  speaker1: 26.60%\n",
            "  speaker2: 73.40%\n",
            "Status: FAILED AUTHENTICATION (Incorrectly identified)\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Enrollment & Authentication Logic\n",
        "\n",
        "# This cell defines the core logic for how a new voice sample can be\n",
        "# authenticated against our trained model.\n",
        "\n",
        "print(\"--- Authentication Logic ---\")\n",
        "\n",
        "if 'model' not in locals() or 'scaler' not in locals():\n",
        "    print(\"ERROR: Model or scaler not trained/initialized. Please run Cell 5 first.\")\n",
        "else:\n",
        "    # Get test files info\n",
        "    test_files_info = [f for f in all_audio_files if f['type'] == 'test']\n",
        "\n",
        "    if not test_files_info:\n",
        "        print(\"No test files found. Please upload test samples in Cell 3.\")\n",
        "    else:\n",
        "        print(\"\\nPerforming authentication on test samples...\")\n",
        "\n",
        "        # Loop through each test file and try to authenticate it\n",
        "        for i, test_file_info in enumerate(test_files_info):\n",
        "            test_audio_path = test_file_info['path']\n",
        "            true_speaker = test_file_info['speaker']\n",
        "\n",
        "            print(f\"\\n--- Test Sample {i+1}: '{os.path.basename(test_audio_path)}' (True speaker: {true_speaker}) ---\")\n",
        "\n",
        "            # Extract MFCCs from the test audio\n",
        "            test_mfcc = extract_mfcc(test_audio_path)\n",
        "\n",
        "            if test_mfcc is not None:\n",
        "                # Reshape for prediction (model expects 2D array: 1 sample, N_MFCC features)\n",
        "                test_mfcc_reshaped = test_mfcc.reshape(1, -1)\n",
        "\n",
        "                # Scale the test features using the same scaler used for training\n",
        "                test_mfcc_scaled = scaler.transform(test_mfcc_reshaped)\n",
        "\n",
        "                # Predict the speaker using the trained model\n",
        "                predicted_speaker = model.predict(test_mfcc_scaled)[0]\n",
        "\n",
        "                # Get prediction probabilities (if using SVC with probability=True or RandomForest)\n",
        "                # This gives a confidence score for each possible speaker.\n",
        "                probabilities = model.predict_proba(test_mfcc_scaled)[0]\n",
        "\n",
        "                # Get the names of all classes (speakers) from the model\n",
        "                class_labels = model.classes_\n",
        "\n",
        "                # Create a dictionary of speaker probabilities\n",
        "                speaker_probabilities = dict(zip(class_labels, probabilities))\n",
        "\n",
        "                print(f\"Predicted Speaker: {predicted_speaker}\")\n",
        "                print(f\"True Speaker: {true_speaker}\")\n",
        "                print(\"Probabilities per speaker:\")\n",
        "                for speaker, prob in speaker_probabilities.items():\n",
        "                    print(f\"  {speaker}: {prob*100:.2f}%\")\n",
        "\n",
        "                if predicted_speaker == true_speaker:\n",
        "                    print(\"Status: AUTHENTICATED (Correctly identified)\")\n",
        "                else:\n",
        "                    print(\"Status: FAILED AUTHENTICATION (Incorrectly identified)\")\n",
        "# Cell 6: Enrollment & Authentication Logic\n",
        "\n",
        "# This cell defines the core logic for how a new voice sample can be\n",
        "# authenticated against our trained model.\n",
        "\n",
        "print(\"--- Authentication Logic ---\")\n",
        "\n",
        "if 'model' not in locals() or 'scaler' not in locals():\n",
        "    print(\"ERROR: Model or scaler not trained/initialized. Please run Cell 5 first.\")\n",
        "else:\n",
        "    # Get test files info\n",
        "    test_files_info = [f for f in all_audio_files if f['type'] == 'test']\n",
        "\n",
        "    if not test_files_info:\n",
        "        print(\"No test files found. Please upload test samples in Cell 3.\")\n",
        "    else:\n",
        "        print(\"\\nPerforming authentication on test samples...\")\n",
        "\n",
        "        # Loop through each test file and try to authenticate it\n",
        "        for i, test_file_info in enumerate(test_files_info):\n",
        "            test_audio_path = test_file_info['path']\n",
        "            true_speaker = test_file_info['speaker']\n",
        "\n",
        "            print(f\"\\n--- Test Sample {i+1}: '{os.path.basename(test_audio_path)}' (True speaker: {true_speaker}) ---\")\n",
        "\n",
        "            # Extract MFCCs from the test audio\n",
        "            test_mfcc = extract_mfcc(test_audio_path)\n",
        "\n",
        "            if test_mfcc is not None:\n",
        "                # Reshape for prediction (model expects 2D array: 1 sample, N_MFCC features)\n",
        "                test_mfcc_reshaped = test_mfcc.reshape(1, -1)\n",
        "\n",
        "                # Scale the test features using the same scaler used for training\n",
        "                test_mfcc_scaled = scaler.transform(test_mfcc_reshaped)\n",
        "\n",
        "                # Predict the speaker using the trained model\n",
        "                predicted_speaker = model.predict(test_mfcc_scaled)[0]\n",
        "\n",
        "                # Get prediction probabilities (if using SVC with probability=True or RandomForest)\n",
        "                # This gives a confidence score for each possible speaker.\n",
        "                probabilities = model.predict_proba(test_mfcc_scaled)[0]\n",
        "\n",
        "                # Get the names of all classes (speakers) from the model\n",
        "                class_labels = model.classes_\n",
        "\n",
        "                # Create a dictionary of speaker probabilities\n",
        "                speaker_probabilities = dict(zip(class_labels, probabilities))\n",
        "\n",
        "                print(f\"Predicted Speaker: {predicted_speaker}\")\n",
        "                print(f\"True Speaker: {true_speaker}\")\n",
        "                print(\"Probabilities per speaker:\")\n",
        "                for speaker, prob in speaker_probabilities.items():\n",
        "                    print(f\"  {speaker}: {prob*100:.2f}%\")\n",
        "\n",
        "                if predicted_speaker == true_speaker:\n",
        "                    print(\"Status: AUTHENTICATED (Correctly identified)\")\n",
        "                else:\n",
        "                    print(\"Status: FAILED AUTHENTICATION (Incorrectly identified)\")\n",
        "            else:\n",
        "                print(f\"  Skipping test sample due to MFCC extraction error: {os.path.basename(test_audio_path)}\")"
      ],
      "id": "kfhMq0WQmGdQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFDfbj5cmGdR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ac5ad1ff-b1a5-41e8-d4a5-e5043e2f9f9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 3) (<ipython-input-6-89ae4667cc38>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-89ae4667cc38>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    Congratulations! You've successfully built a basic Voice Authentication System that runs entirely on CPU in Google Colab, carefully managing library versions.\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 3)\n"
          ]
        }
      ],
      "source": [
        "# Conclusion & Next Steps\n",
        "\n",
        "Congratulations! You've successfully built a basic Voice Authentication System that runs entirely on CPU in Google Colab, carefully managing library versions.\n",
        "\n",
        "### Summary of What We Achieved:\n",
        "\n",
        "* **Robust Setup:** Handled common NumPy and `dlib` installation issues in Colab by enforcing a stable environment.\n",
        "* **Audio Processing:** Learned to load audio files and extract key features (MFCCs).\n",
        "* **Machine Learning Workflow:** Implemented a full ML pipeline from data preparation and feature extraction to model training and prediction.\n",
        "* **Speaker Recognition:** Developed a system that can, with varying degrees of accuracy, identify speakers based on their voice.\n",
        "\n",
        "### Further Enhancements & Exploration:\n",
        "\n",
        "This is just the beginning! Here are some ideas to take this project further:\n",
        "\n",
        "1.  **More Data:** The accuracy of ML models heavily depends on the amount and quality of training data. Try uploading more enrollment samples per speaker, and more speakers overall.\n",
        "2.  **Advanced Features:**\n",
        "    * Explore other audio features like Chroma, Tonal Centroid Feature (Tonnetz), Zero Crossing Rate, Spectral Centroid, etc.\n",
        "    * Instead of averaging MFCCs, you could use sequences of MFCCs with Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs) for more complex models.\n",
        "3.  **Different Classifiers:** Experiment with other `scikit-learn` classifiers like `KNeighborsClassifier`, `GaussianNB`, or `XGBoost` (requires `pip install xgboost`).\n",
        "4.  **Deep Learning for Voice:** For higher accuracy, especially with more data, you could move to deep learning architectures. This would involve libraries like `TensorFlow` or `PyTorch` and specialized voice models.\n",
        "5.  **Robustness:**\n",
        "    * Implement noise reduction techniques on audio.\n",
        "    * Consider voice activity detection (VAD) to ensure only speech is processed.\n",
        "6.  **User Interface:** Build a simple web interface (e.g., using `Gradio` or `Streamlit` in Colab) to make the demo more interactive.\n",
        "7.  **\"Imposter\" Detection:** Modify the authentication logic to not just predict *who* the speaker is, but also determine *if* the speaker is one of the enrolled individuals (i.e., reject imposters). This usually involves setting a confidence threshold.\n",
        "\n",
        "Keep experimenting and have fun!"
      ],
      "id": "mFDfbj5cmGdR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpYA3noXmGdT"
      },
      "source": [
        "## 8. Next Steps & Extensions\n",
        "\n",
        "- **Collect More Data:** 10+ utterances per speaker improves robustness.\n",
        "- **Feature Variations:** Delta MFCC, spectral contrast, or PLP features.\n",
        "- **Classifier Experiments:** SVM (`sklearn.svm.SVC`), GMM (e.g., `sklearn.mixture.GaussianMixture` per speaker), or Random Forest.\n",
        "- **Real-Time Mic Capture:** Use JavaScript/HTML in a web app to record short clips and send to this pipeline via an API.\n",
        "- **Threshold Tuning:** Adjust the threshold for `authenticate()` based on ROC curve to minimize false acceptance/rejection.\n",
        "- **Embed in an App:** Export KNN to ONNX or pickle, then load in a Flask/Streamlit front-end for a complete demo.\n"
      ],
      "id": "GpYA3noXmGdT"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}